services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.4
    hostname: zookeeper
    networks:
      - docker-net
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.4
    hostname: kafka
    networks:
      - docker-net
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./plugins:/usr/share/kafka/plugins

  minio:
    image: minio/minio:RELEASE.2024-05-10T01-41-38Z
    networks:
      - docker-net
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./minio-data:/data 
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    command: server /data --console-address ":9001"

  connect:
    image: confluentinc/cp-kafka-connect:7.5.4
    hostname: connect
    user: root
    depends_on:
      - kafka
      - minio
    networks:
      - docker-net
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/kafka/plugins/kafka-connect-s3"
      CONNECT_GROUP_ID: "quickstart"
      CONNECT_CONFIG_STORAGE_TOPIC: "quickstart-config"
      CONNECT_OFFSET_STORAGE_TOPIC: "quickstart-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "quickstart-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNALVALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_CONFLUENT_LICENSE: "ABC123XYZ737BVT"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CLASSPATH: "/usr/share/kafka/plugins/kafka-connect-s3"
    volumes:
      - ./plugins:/usr/share/kafka/plugins

  # rhel_container:
  #   image: python:3.8
  #   container_name: rhel_container
  #   # For Apple silicon M1, M2, M3 use linux/x86_64 platform for the rhel container as it needs to be compatible with the contents of the /opt/spark directory 
  #   platform: linux/x86_64
  #   networks:
  #     - docker-net
  #   environment:
  #     JAVA_HOME: /opt/spark/jdk-22.0.1
  #     SPARK_HOME: /opt/spark/spark-3.5.1-bin-hadoop3
  #     PATH: /opt/spark/spark-3.5.1-bin-hadoop3/bin:$PATH
  #   command: >
  #     sh -c "
  #     pip install --upgrade pip &&
  #     pip install kafka-python boto3 pyspark &&
  #     tail -f /dev/null
  #     "
  #   stdin_open: true
  #   tty: true
  #   volumes:
  #     - ./scripts:/scripts
  #     - ./spark-client:/opt/spark

  spark-master:
    image: bitnami/spark:3.5.1
    container_name: spark-master
    hostname: spark-master
    platform: linux/arm64/v8
    environment:
      SPARK_MODE: master
    networks:
      - docker-net
    ports:
      - "8080:8080"
      - "7077:7077"      
    command: [ "/opt/bitnami/scripts/spark/entrypoint.sh", "/opt/bitnami/scripts/spark/run.sh" ]

  spark-worker:
    image: bitnami/spark:3.5.1
    container_name: spark-worker
    hostname: spark-worker
    platform: linux/arm64/v8
    networks:
      - docker-net
    ports:
      - "8081:8081"
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077     
    command: [ "/opt/bitnami/scripts/spark/entrypoint.sh", "/opt/bitnami/scripts/spark/run.sh" ]

  backend:
    image: tiangolo/uvicorn-gunicorn-fastapi:python3.10
    platform: linux/x86_64
    volumes:
      - ./llm_spark/backend:/app
      - ./spark-client:/opt/spark
    environment:
      - MODULE_NAME=app
      - VARIABLE_NAME=app
      - MODEL_PATH=/app/llm/codellama-7b-instruct.Q4_K_M.gguf
      - SPARK_MASTER=spark://spark-master:7077
      - JAVA_HOME=/opt/spark/jdk-22.0.1
      - SPARK_HOME=/opt/spark/spark-3.5.1-bin-hadoop3
      - PATH=/opt/spark/spark-3.5.1-bin-hadoop3/bin:$PATH
    networks:
      - docker-net
    command: >
      /bin/bash -c "
        apt-get update &&
        apt-get install -y cmake build-essential &&
        pip install --upgrade pip &&
        pip install --no-cache-dir --verbose -r /app/requirements.txt &&
        uvicorn app:app --host 0.0.0.0 --port 80
      "
    ports:
      - "8000:80"
    depends_on:
      - spark-master

  frontend:
    image: nginx:alpine
    volumes:
      - ./llm_spark/frontend:/usr/share/nginx/html:ro
    networks:
      - docker-net
    ports:
      - "8082:80"
      
networks:
  docker-net:
volumes:
  minio-data:
